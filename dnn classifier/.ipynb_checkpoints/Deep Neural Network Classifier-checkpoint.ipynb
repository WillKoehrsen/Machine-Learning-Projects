{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is great for creating neural networks, and Scikit-learn is great for a wide background of machine learning tasks. Would not it be great if we could combine the two and create a deep neural network classifier in tensorflow that works in Scikit-learn? We could then use Grid Search Cross Validation to find the optimal parameters for our model. We will be building a classifier so we will need the BaseEstimator and the ClassifierMixIn. CIFAR-10 Dataset. From Udacity Machine Learning Engineering Nanodegree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This class inherits from both BaseEstimator and ClassifierMixin in Sklearn\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=4, n_neurons=50, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, max_checks_without_progress=20,\n",
    "                 show_progress=10, tensorboard_logdir=None, random_state=42):\n",
    "        # Initializer the class with sensible default hyperparameters\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_checks_without_progress = max_checks_without_progress\n",
    "        self.show_progress = show_progress\n",
    "        self.random_state = random_state\n",
    "        self.tensorboard_logdir = tensorboard_logdir\n",
    "        self._session = None #Instance variables preceded by _ are private members\n",
    "        \n",
    "    def _dnn(self, inputs):\n",
    "        # This method builds the hidden layers \n",
    "        # Provides for implmentation of batch normalization and dropout\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            # Apply dropout if specified\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, rate=self.dropout_rate, training=self._training)\n",
    "            # Create the hidden layer\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons, activation=self.activation, \n",
    "                                     kernel_initializer=self.initializer, \n",
    "                                     name = \"hidden%d\" % (layer + 1))\n",
    "            # Apply batch normalization if specified\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "                \n",
    "            # Apply activation function\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer+1))\n",
    "        return inputs\n",
    "        \n",
    "    def _construct_graph(self, n_inputs, n_outputs):\n",
    "        # This method builds the Tensorflow computation graph\n",
    "        if self.random_state:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "         \n",
    "        # PLaceholders for training data\n",
    "        X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "        \n",
    "        # All labels are converted to a list with integers\n",
    "        y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "        \n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
    "        else:\n",
    "            self._training = None\n",
    "        \n",
    "        # After DNN but before output layer\n",
    "        pre_output = self._dnn(X)\n",
    "        \n",
    "        # Output logits and probabilities\n",
    "        logits = tf.layers.dense(pre_output, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        probabilities = tf.nn.softmax(logits, name=\"probabilities\")\n",
    "        \n",
    "        # Cross entropy function is cost function and loss is average cross entropy\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        # Optimizer and training operation\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        \n",
    "        # Needed for batch normalization\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            training_op = optimizer.minimize(loss)\n",
    "        \n",
    "        correct = tf.nn.in_top_k(logits, y, 1)    \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # For tensorboard visualization\n",
    "        if self.tensorboard_logdir:\n",
    "            now = datetime.utcnow().strftime(\"%Y%M%d-%H%M%S\")\n",
    "            root_logdir = self.tensorboard_logdir\n",
    "            tb_logdir = root_logdir + \"/run-{}\".format(now)\n",
    "            \n",
    "            cost_summary = tf.summary.scalar(\"validation_loss\", loss)\n",
    "            acc_summary = tf.summary.scalar(\"validation_accuracy\", accuracy)\n",
    "            merged_summary = tf.summary.merge_all()\n",
    "            file_writer = tf.summary.FileWriter(tb_logdir, tf.get_default_graph())\n",
    "            \n",
    "            self._merged_summary = merged_summary\n",
    "            self._file_writer = file_writer\n",
    "        \n",
    "        self._X, self._y = X, y\n",
    "        self._logits = logits\n",
    "        self._probabilities = probabilities\n",
    "        self._loss = loss\n",
    "        self._training_op = training_op\n",
    "        self._accuracy = accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "        \n",
    "        \n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "            \n",
    "    def _get_model_parameters(self):\n",
    "        # Retrieves the values of all the variables in the network \n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "    \n",
    "    def _restore_model_parameters(self, model_params):\n",
    "        gvar_names = list(model_params.keys())\n",
    "        \n",
    "        '''graph.get_operation_by_name(operation).inputs returns the input to the given operation\n",
    "        because these are all assignment operations, the second argument to inputs is the value'''\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "        \n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        # Main function to train the model using the training data. Will use early stopping if X_valid and y_valid are given\n",
    "        self.close_session()\n",
    "        n_inputs = X.shape[1]\n",
    "        \n",
    "        # If labels are provided in one_hot form, convert to integer class labels\n",
    "        y = np.array(y)\n",
    "        y_valid = np.array(y_valid)\n",
    "        \n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y, axis=1)\n",
    "     \n",
    "        if len(y_valid.shape) == 2:\n",
    "            y_valid = np.argmax(y_valid, axis=1)\n",
    "\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "    \n",
    "        # Tensorflow expects labels from 0 to n_classes - 1. Labels might need to be converted\n",
    "        self.class_to_index_ = {label: index for index, label in enumerate(self.classes_)}\n",
    "        labels = [self.class_to_index_[label] for label in y]\n",
    "        y = np.array(labels, dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "            \n",
    "        with self._graph.as_default():\n",
    "            self._construct_graph(n_inputs, n_outputs)\n",
    "            \n",
    "        # For use with early stopping\n",
    "        checks_without_progress= 0 \n",
    "        best_loss = np.float(\"inf\")\n",
    "        best_parameters = None\n",
    "        \n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            # Initialize all variables\n",
    "            self._init.run()\n",
    "            num_instances = X.shape[0]\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(num_instances)\n",
    "                for rnd_indices in np.array_split(rnd_idx, num_instances // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    train_acc, _ = sess.run([self._accuracy, self._training_op], feed_dict)\n",
    "                # Early stopping implementation\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    feed_dict_valid = {self._X: X_valid, self._y: y_valid}\n",
    "                    if self.tensorboard_logdir:\n",
    "                        val_acc, val_loss, summary = sess.run([self._accuracy, self._loss, self._merged_summary], feed_dict=feed_dict_valid)\n",
    "                        self._file_writer.add_summary(summary, epoch)\n",
    "                    else:\n",
    "                        val_acc, val_loss = sess.run([self._accuracy, self._loss], feed_dict=feed_dict_valid)\n",
    "                    \n",
    "                    # Show training progress\n",
    "                    if self.show_progress:\n",
    "                        if epoch % self.show_progress == 0:\n",
    "                            print(\"Epoch: {} Current training accuracy: {:.4f} Validation Accuracy: {:.4f} Validation Loss {:.6f}\".format(\n",
    "                                epoch+1, train_acc, val_acc, val_loss))\n",
    "\n",
    "                    # Check to see if model is improving \n",
    "                    if val_loss < best_loss:\n",
    "                        best_loss = val_loss\n",
    "                        checks_without_progress = 0\n",
    "                        best_parameters = self._get_model_parameters()\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "\n",
    "                    if checks_without_progress > self.max_checks_without_progress:\n",
    "                        print(\"Stopping Early! Loss has not improved in {} epochs\".format(\n",
    "                                self.max_checks_without_progress))\n",
    "                        break\n",
    "                # No validation set provided\n",
    "                else:\n",
    "                    if self.show_progress:\n",
    "                        \n",
    "                        if epoch % self.show_progress == 0:\n",
    "                            logit_values = sess.run(self._logits, feed_dict={self._X: X_batch})\n",
    "                            print(\"Epoch: {} Current training accuracy: {:.4f}\".format(\n",
    "                                epoch+1, train_acc))\n",
    "                        \n",
    "            # In the case of early stopping, restore the best weight values\n",
    "            if best_parameters:\n",
    "                self._restore_model_parameters(best_parameters)\n",
    "                return self\n",
    "            \n",
    "    def predict_probabilities(self, X):\n",
    "        if not self._session:\n",
    "            # Method inherited from BaseEstimator\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._probabilities.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_probabilities(X), axis=1)\n",
    "        predictions = np.array([[self.classes_[class_index]] for class_index in class_indices], dtype=np.int32)\n",
    "        return np.reshape(predictions, (-1,))\n",
    "        \n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_valid = mnist.validation.images\n",
    "y_valid = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn = DNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Current training accuracy: 0.9500 Validation Accuracy: 0.9290 Validation Loss 0.277416\n",
      "Epoch: 11 Current training accuracy: 0.9000 Validation Accuracy: 0.9480 Validation Loss 0.280415\n",
      "Epoch: 21 Current training accuracy: 0.9500 Validation Accuracy: 0.9430 Validation Loss 0.499475\n",
      "Epoch: 31 Current training accuracy: 0.5000 Validation Accuracy: 0.5100 Validation Loss 1.310640\n",
      "Stopping Early! Loss has not improved in 20 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x0000015991148D08>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x000001599725E2F0>,\n",
       "       learning_rate=0.01, max_checks_without_progress=20,\n",
       "       n_hidden_layers=4, n_neurons=50,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42, show_progress=10, tensorboard_logdir=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.fit(X_train, y_train, 100, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = dnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.equal(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'n_hidden_layers': [3, 4, 5, 6],\n",
    "    'n_neurons': [50, 100, 150],\n",
    "    'batch_size': [64, 256],\n",
    "    'learning_rate':[0.01, 0.005],\n",
    "    'activation': [tf.nn.elu, tf.nn.relu],\n",
    "    'max_checks_without_progress': [15, 20, 25],\n",
    "    'batch_norm_momentum': [None, 0.9],\n",
    "    'dropout_rate': [None, 0.5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DNNClassifier(show_progress=None), parameter_grid,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1152 candidates, totalling 3456 fits\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50, total= 5.0min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50, total= 5.0min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=50, total= 5.0min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100, total= 5.1min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100, total= 5.1min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=100, total= 5.1min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150, total= 5.5min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150, total= 5.5min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=3, n_neurons=150, total= 5.5min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50, total= 5.2min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50, total= 5.2min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=50, total= 5.2min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100, total= 5.4min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100, total= 5.4min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=100, total= 5.4min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=4, n_neurons=150, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50, total= 5.2min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50, total= 5.2min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=50, total= 5.4min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100, total= 5.7min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100, total= 5.7min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=100, total= 5.7min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150, total= 6.0min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=5, n_neurons=150, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50, total= 5.6min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50, total= 5.5min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=50, total= 5.6min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=100, total= 5.9min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150, total= 6.3min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150, total=344.4min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150 \n",
      "[CV]  activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=15, n_hidden_layers=6, n_neurons=150, total= 6.6min\n",
      "[CV] activation=<function elu at 0x0000015991148D08>, batch_norm_momentum=None, batch_size=64, dropout_rate=None, learning_rate=0.01, max_checks_without_progress=20, n_hidden_layers=3, n_neurons=50 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-79fead2bcf0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6753bf44fbe2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[1;31m# Early stopping implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Will Koehrsen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_excel(\"datasets/titanic3.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode the categorical variables\n",
    "titanic = pd.get_dummies(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "      <th>name_Abbing, Mr. Anthony</th>\n",
       "      <th>name_Abbott, Master. Eugene Joseph</th>\n",
       "      <th>name_Abbott, Mr. Rossmore Edward</th>\n",
       "      <th>...</th>\n",
       "      <th>home.dest_Wimbledon Park, London / Hayling Island, Hants</th>\n",
       "      <th>home.dest_Windsor, England New York, NY</th>\n",
       "      <th>home.dest_Winnipeg, MB</th>\n",
       "      <th>home.dest_Winnipeg, MN</th>\n",
       "      <th>home.dest_Woodford County, KY</th>\n",
       "      <th>home.dest_Worcester, England</th>\n",
       "      <th>home.dest_Worcester, MA</th>\n",
       "      <th>home.dest_Yoevil, England / Cottage Grove, OR</th>\n",
       "      <th>home.dest_Youngstown, OH</th>\n",
       "      <th>home.dest_Zurich, Switzerland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows  2841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pclass  survived      age  sibsp  parch      fare   body  \\\n",
       "0        1         1  29.0000      0      0  211.3375    NaN   \n",
       "1        1         1   0.9167      1      2  151.5500    NaN   \n",
       "2        1         0   2.0000      1      2  151.5500    NaN   \n",
       "3        1         0  30.0000      1      2  151.5500  135.0   \n",
       "4        1         0  25.0000      1      2  151.5500    NaN   \n",
       "5        1         1  48.0000      0      0   26.5500    NaN   \n",
       "6        1         1  63.0000      1      0   77.9583    NaN   \n",
       "7        1         0  39.0000      0      0    0.0000    NaN   \n",
       "8        1         1  53.0000      2      0   51.4792    NaN   \n",
       "9        1         0  71.0000      0      0   49.5042   22.0   \n",
       "10       1         0  47.0000      1      0  227.5250  124.0   \n",
       "11       1         1  18.0000      1      0  227.5250    NaN   \n",
       "12       1         1  24.0000      0      0   69.3000    NaN   \n",
       "13       1         1  26.0000      0      0   78.8500    NaN   \n",
       "14       1         1  80.0000      0      0   30.0000    NaN   \n",
       "\n",
       "    name_Abbing, Mr. Anthony  name_Abbott, Master. Eugene Joseph  \\\n",
       "0                          0                                   0   \n",
       "1                          0                                   0   \n",
       "2                          0                                   0   \n",
       "3                          0                                   0   \n",
       "4                          0                                   0   \n",
       "5                          0                                   0   \n",
       "6                          0                                   0   \n",
       "7                          0                                   0   \n",
       "8                          0                                   0   \n",
       "9                          0                                   0   \n",
       "10                         0                                   0   \n",
       "11                         0                                   0   \n",
       "12                         0                                   0   \n",
       "13                         0                                   0   \n",
       "14                         0                                   0   \n",
       "\n",
       "    name_Abbott, Mr. Rossmore Edward              ...                \\\n",
       "0                                  0              ...                 \n",
       "1                                  0              ...                 \n",
       "2                                  0              ...                 \n",
       "3                                  0              ...                 \n",
       "4                                  0              ...                 \n",
       "5                                  0              ...                 \n",
       "6                                  0              ...                 \n",
       "7                                  0              ...                 \n",
       "8                                  0              ...                 \n",
       "9                                  0              ...                 \n",
       "10                                 0              ...                 \n",
       "11                                 0              ...                 \n",
       "12                                 0              ...                 \n",
       "13                                 0              ...                 \n",
       "14                                 0              ...                 \n",
       "\n",
       "    home.dest_Wimbledon Park, London / Hayling Island, Hants  \\\n",
       "0                                                   0          \n",
       "1                                                   0          \n",
       "2                                                   0          \n",
       "3                                                   0          \n",
       "4                                                   0          \n",
       "5                                                   0          \n",
       "6                                                   0          \n",
       "7                                                   0          \n",
       "8                                                   0          \n",
       "9                                                   0          \n",
       "10                                                  0          \n",
       "11                                                  0          \n",
       "12                                                  0          \n",
       "13                                                  0          \n",
       "14                                                  0          \n",
       "\n",
       "    home.dest_Windsor, England New York, NY  home.dest_Winnipeg, MB  \\\n",
       "0                                         0                       0   \n",
       "1                                         0                       0   \n",
       "2                                         0                       0   \n",
       "3                                         0                       0   \n",
       "4                                         0                       0   \n",
       "5                                         0                       0   \n",
       "6                                         0                       0   \n",
       "7                                         0                       0   \n",
       "8                                         0                       0   \n",
       "9                                         0                       0   \n",
       "10                                        0                       0   \n",
       "11                                        0                       0   \n",
       "12                                        0                       0   \n",
       "13                                        0                       0   \n",
       "14                                        0                       0   \n",
       "\n",
       "    home.dest_Winnipeg, MN  home.dest_Woodford County, KY  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "5                        0                              0   \n",
       "6                        0                              0   \n",
       "7                        0                              0   \n",
       "8                        0                              0   \n",
       "9                        0                              0   \n",
       "10                       0                              0   \n",
       "11                       0                              0   \n",
       "12                       0                              0   \n",
       "13                       0                              0   \n",
       "14                       0                              0   \n",
       "\n",
       "    home.dest_Worcester, England  home.dest_Worcester, MA  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "3                              0                        0   \n",
       "4                              0                        0   \n",
       "5                              0                        0   \n",
       "6                              0                        0   \n",
       "7                              0                        0   \n",
       "8                              0                        0   \n",
       "9                              0                        0   \n",
       "10                             0                        0   \n",
       "11                             0                        0   \n",
       "12                             0                        0   \n",
       "13                             0                        0   \n",
       "14                             0                        0   \n",
       "\n",
       "    home.dest_Yoevil, England / Cottage Grove, OR  home.dest_Youngstown, OH  \\\n",
       "0                                               0                         0   \n",
       "1                                               0                         0   \n",
       "2                                               0                         0   \n",
       "3                                               0                         0   \n",
       "4                                               0                         0   \n",
       "5                                               0                         0   \n",
       "6                                               0                         0   \n",
       "7                                               0                         0   \n",
       "8                                               0                         0   \n",
       "9                                               0                         0   \n",
       "10                                              0                         0   \n",
       "11                                              0                         0   \n",
       "12                                              0                         0   \n",
       "13                                              0                         0   \n",
       "14                                              0                         0   \n",
       "\n",
       "    home.dest_Zurich, Switzerland  \n",
       "0                               0  \n",
       "1                               0  \n",
       "2                               0  \n",
       "3                               0  \n",
       "4                               0  \n",
       "5                               0  \n",
       "6                               0  \n",
       "7                               0  \n",
       "8                               0  \n",
       "9                               0  \n",
       "10                              0  \n",
       "11                              0  \n",
       "12                              0  \n",
       "13                              0  \n",
       "14                              0  \n",
       "\n",
       "[15 rows x 2841 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.array(titanic.survived)\n",
    "X_train = np.array(titanic.drop(['survived','body'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25)\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 2839)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2) (?,)\n",
      "[[-0.6945591  -0.27741131]\n",
      " [ 0.55506277 -1.74777567]\n",
      " [ 0.22178344 -1.96339321]\n",
      " [ 0.41168994 -2.15936828]\n",
      " [ 0.36622247 -2.13734365]\n",
      " [-2.55559683  0.22118194]\n",
      " [ 0.06851538 -1.97339797]\n",
      " [-0.02794256 -1.72518957]\n",
      " [-1.25824296 -0.43340808]\n",
      " [-0.62253076 -1.23301649]\n",
      " [ 0.33787981 -1.78640437]\n",
      " [ 0.18262132 -2.03559995]\n",
      " [ 0.35602117 -2.39031053]\n",
      " [ 0.34073466 -1.93704069]\n",
      " [-0.42875868 -1.19811189]\n",
      " [-0.84668756  0.78874898]\n",
      " [ 0.20234995 -1.93186474]\n",
      " [-0.45010939 -0.68264592]\n",
      " [ 0.57296079 -2.4077642 ]\n",
      " [ 0.17747435 -1.94662905]]\n",
      "Epoch: 1 Current training accuracy: 0.8000\n",
      "[[ -3.70211792   9.03184509]\n",
      " [ -3.14918947   7.45809507]\n",
      " [ -1.79877329  -8.5555191 ]\n",
      " [ -4.92379522  10.57016945]\n",
      " [  0.27844739 -12.63922596]\n",
      " [ -4.82343817  10.75830173]\n",
      " [ -2.7182219    5.95796108]\n",
      " [ -2.36015511   7.45641041]\n",
      " [  0.45906484 -14.51298046]\n",
      " [ -2.53913903   6.87260532]\n",
      " [  0.28568852 -12.4280653 ]\n",
      " [  0.26281953  -9.28075504]\n",
      " [  0.1383355  -14.26092911]\n",
      " [  0.26615754 -14.66796589]\n",
      " [  0.01501369 -11.45205784]\n",
      " [  0.18373613  -7.83391428]\n",
      " [  0.52228791 -12.29183102]\n",
      " [ -1.48209071   5.67054033]\n",
      " [ -0.33486694 -13.48533344]\n",
      " [ -1.47537255   7.12398911]]\n",
      "Epoch: 11 Current training accuracy: 1.0000\n",
      "[[ -0.86964995 -12.1404705 ]\n",
      " [  0.06142659 -15.66258812]\n",
      " [  0.48935133 -14.70846844]\n",
      " [ -0.85482484 -12.12077808]\n",
      " [ -3.93979335  10.01053333]\n",
      " [ -4.77352762  12.21608925]\n",
      " [  0.29331163 -12.55579662]\n",
      " [ -0.33963239 -17.86494064]\n",
      " [ -2.99178529   7.96787167]\n",
      " [ -4.64318848  11.1282959 ]\n",
      " [  0.13975862 -19.64042282]\n",
      " [ -7.28019619  16.64977455]\n",
      " [ -3.64144683   9.36470509]\n",
      " [  0.44396853 -15.10553551]\n",
      " [  0.0598737  -11.10913944]\n",
      " [  0.10394981 -17.80678368]\n",
      " [ -0.99082571 -17.33790398]\n",
      " [ -3.32747436   8.32095528]\n",
      " [ -5.31497669  12.62183857]\n",
      " [ -4.374403    10.94109726]]\n",
      "Epoch: 21 Current training accuracy: 1.0000\n",
      "[[ -4.6228466   11.13089371]\n",
      " [  4.03114223  -8.85254097]\n",
      " [  0.49446341 -14.30776119]\n",
      " [  0.7654835  -14.16740417]\n",
      " [ -1.43751252 -19.29255295]\n",
      " [  0.31238577 -18.22278786]\n",
      " [ -4.12344217   9.82408047]\n",
      " [ -7.9323597   17.83019257]\n",
      " [ -5.00754404  10.54628181]\n",
      " [ -0.37612438 -15.58301735]\n",
      " [ -5.24028492  12.2837801 ]\n",
      " [ -0.6598534  -18.57913399]\n",
      " [  0.9048394  -14.42847824]\n",
      " [  2.90320134  -8.96696472]\n",
      " [ -3.94977379  10.15730858]\n",
      " [ -6.57751417  15.61157131]\n",
      " [  2.54239798  -6.98559141]\n",
      " [  0.73559314 -16.20651627]\n",
      " [  4.80162096  -8.3599329 ]\n",
      " [  0.49824968 -11.80202293]]\n",
      "Epoch: 31 Current training accuracy: 1.0000\n",
      "[[ -4.35598564   9.31548309]\n",
      " [  4.44099426  -8.66797543]\n",
      " [  0.60041052 -18.13666916]\n",
      " [ -4.93584204  10.92592239]\n",
      " [  2.01960802  -8.66859436]\n",
      " [  0.75063032 -18.58023453]\n",
      " [ -9.04592991  18.4789772 ]\n",
      " [ -3.61347985   9.51153183]\n",
      " [  1.20009172 -18.48714256]\n",
      " [ -1.24909103 -23.14939308]\n",
      " [ -6.95237255  15.58762264]\n",
      " [ -4.59106922  11.11240768]\n",
      " [ -5.09445715  11.05172539]\n",
      " [  2.56001544 -11.80006409]\n",
      " [  0.68634117 -16.26738167]\n",
      " [ -0.45872119 -20.73642731]\n",
      " [ -4.86539078  11.92460251]\n",
      " [ -8.07891083  17.86558723]\n",
      " [ -0.82657695 -15.12517262]\n",
      " [ -3.64764738   8.61847115]]\n",
      "Epoch: 41 Current training accuracy: 1.0000\n",
      "[[  0.50945163 -22.98192596]\n",
      " [ -1.44078422 -23.79644966]\n",
      " [ -4.87310362  10.69247532]\n",
      " [  4.43664694  -9.69511509]\n",
      " [ -6.20161963  13.8397665 ]\n",
      " [  0.99327111 -14.54729271]\n",
      " [ -6.80845499  15.30141926]\n",
      " [  0.91480416 -20.29905319]\n",
      " [  5.12467718  -8.29095268]\n",
      " [  2.16583395 -12.11447048]\n",
      " [ -0.65661067 -18.52784157]\n",
      " [ -3.73746419   9.69105339]\n",
      " [ -8.32834911  18.23325539]\n",
      " [  1.10118449 -18.24689293]\n",
      " [  1.04989529 -17.78626823]\n",
      " [  1.83453429 -12.94067097]\n",
      " [  0.5492872  -16.46897697]\n",
      " [  0.63935184 -17.2528286 ]\n",
      " [ -5.92550087  13.1921196 ]\n",
      " [ -5.80653238  13.75295067]]\n",
      "Epoch: 51 Current training accuracy: 1.0000\n",
      "[[ -5.40520859e+00   1.24095831e+01]\n",
      " [  3.15598696e-02  -1.72451305e+01]\n",
      " [  7.30733871e-01  -1.84830933e+01]\n",
      " [  1.82208419e-01  -1.76735992e+01]\n",
      " [  1.74616957e+00  -1.65360622e+01]\n",
      " [  7.36688495e-01  -1.59042988e+01]\n",
      " [  9.64023843e-02  -1.66611481e+01]\n",
      " [  5.87784290e-01  -1.98174553e+01]\n",
      " [ -6.71969891e+00   1.38165865e+01]\n",
      " [ -6.21874046e+00   1.46525726e+01]\n",
      " [  6.52029634e-01  -1.64031734e+01]\n",
      " [  4.35504150e+00  -9.61454487e+00]\n",
      " [  1.09662306e+00  -1.21762371e+01]\n",
      " [ -6.10519028e+00   1.37202740e+01]\n",
      " [ -7.12395573e+00   1.57382460e+01]\n",
      " [  2.02135420e+00  -1.01267824e+01]\n",
      " [  1.19638383e+00  -1.71627636e+01]\n",
      " [  4.37836379e-01  -1.92022457e+01]\n",
      " [  6.79741025e-01  -2.35533867e+01]\n",
      " [  2.32307799e-02  -1.40243940e+01]]\n",
      "Epoch: 61 Current training accuracy: 1.0000\n",
      "[[ -5.65886641e+00   1.27593813e+01]\n",
      " [ -7.25047398e+00   1.57576838e+01]\n",
      " [  3.59952450e+00  -8.78345203e+00]\n",
      " [  5.05107582e-01  -1.99301701e+01]\n",
      " [  1.52281332e+00  -1.71259022e+01]\n",
      " [ -9.03378487e+00   1.98763580e+01]\n",
      " [  4.74597168e+00  -9.61209583e+00]\n",
      " [ -5.32451200e+00   1.14512129e+01]\n",
      " [ -4.61571360e+00   6.86693287e+00]\n",
      " [  1.19420066e-02  -2.09722919e+01]\n",
      " [  5.64944088e-01  -1.84640312e+01]\n",
      " [  1.30448118e-01  -1.84461517e+01]\n",
      " [ -4.68820667e+00   1.00684137e+01]\n",
      " [  1.24404991e+00  -1.67961464e+01]\n",
      " [  4.67333460e+00  -7.78855562e+00]\n",
      " [ -6.93565083e+00   1.48954220e+01]\n",
      " [ -3.83956492e-01  -2.32619553e+01]\n",
      " [  1.81538254e-01  -1.28506870e+01]\n",
      " [  5.92831075e-01  -1.82187805e+01]\n",
      " [ -4.27297056e-01  -1.63318367e+01]]\n",
      "Epoch: 71 Current training accuracy: 1.0000\n",
      "[[ -0.544716   -16.84945297]\n",
      " [ -0.37880227 -20.57341576]\n",
      " [  1.24943995 -18.58930969]\n",
      " [ -5.65124321  12.64761257]\n",
      " [  0.81296611 -18.95072556]\n",
      " [ -6.43637085  14.01627541]\n",
      " [  1.24713349 -18.08073807]\n",
      " [ -4.89045286  11.66349125]\n",
      " [ -6.05516863  14.10377979]\n",
      " [  1.23340487 -19.31644058]\n",
      " [  1.19929254 -19.66931725]\n",
      " [  0.88475263 -19.20238686]\n",
      " [  2.10557151 -13.72551537]\n",
      " [  1.40131199 -14.65449238]\n",
      " [  5.96042061  -9.04244137]\n",
      " [ -6.2614975   14.63263798]\n",
      " [ -7.88597631  17.11094856]\n",
      " [  1.40185142 -16.70732498]\n",
      " [  1.51313496 -19.02880859]\n",
      " [  0.82664633 -15.65463161]]\n",
      "Epoch: 81 Current training accuracy: 1.0000\n",
      "[[ -5.28381538  10.87665081]\n",
      " [ -7.38438511  15.63337517]\n",
      " [  1.33280849 -16.51312637]\n",
      " [ -7.82188749  16.50331306]\n",
      " [  0.59698057 -20.15128517]\n",
      " [ -9.39974213  20.42451668]\n",
      " [ -9.39091682  20.11808777]\n",
      " [  1.55245531 -18.45594978]\n",
      " [ -5.49405527  12.8192215 ]\n",
      " [ -7.74411631  16.70757484]\n",
      " [ -6.23566723  13.70330429]\n",
      " [  1.55380404 -17.57445145]\n",
      " [  1.4384495  -20.74867058]\n",
      " [ -0.76047081 -21.23514938]\n",
      " [  1.03341687 -20.30682755]\n",
      " [  1.18349552 -14.80228424]\n",
      " [  1.38181353 -17.42570496]\n",
      " [ -0.40147999 -16.57583427]\n",
      " [  1.09932995 -16.54833603]\n",
      " [  1.61530864 -14.082757  ]]\n",
      "Epoch: 91 Current training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "dnn = DNNClassifier()\n",
    "dnn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92682926829268297"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn.predict(X_test)\n",
    "\n",
    "np.mean(np.equal(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnn_clf = DNNClassifier(show_progress=None)\n",
    "\n",
    "param_distributions = {\n",
    "    'n_hidden_layers': [3, 4, 5],\n",
    "    'n_neurons': [20, 50, 100],\n",
    "    'activation': [tf.nn.elu, tf.nn.relu],\n",
    "    'learning_rate': [0.01, 0.005],\n",
    "    'batch_norm_momentum': [None, 0.9],\n",
    "    'dropout_rate': [None, 0.25]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(dnn_clf, param_distributions, n_iter=100, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total= 1.0min\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  55.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  52.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  46.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  42.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  43.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  39.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  30.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  24.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  24.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  28.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  31.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  34.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  46.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  57.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  58.8s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total= 1.0min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  43.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  40.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  51.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  49.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  50.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  40.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  30.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  16.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  15.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  15.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  45.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  50.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  53.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  51.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  38.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  39.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  26.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  26.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  19.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  19.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  20.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  20.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  21.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  21.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  47.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  46.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  48.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  35.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  35.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  34.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  49.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  51.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  49.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  19.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  35.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  35.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  37.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  20.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  16.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  51.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  49.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  49.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  22.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  22.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  38.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  38.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  41.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  42.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  43.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  42.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  52.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  19.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  19.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  36.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  37.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  35.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  51.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  41.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  42.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  44.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  39.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  50.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  50.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  50.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  18.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  18.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  18.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  15.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  15.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  15.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  42.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  42.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  47.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  26.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  20.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  21.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  20.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  39.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  39.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  39.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  17.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  22.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  47.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  47.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  47.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  18.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  19.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  15.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  15.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  15.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total= 1.0min\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total= 1.0min\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  55.5s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.8s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  21.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  24.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  24.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  24.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  39.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  38.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  38.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  25.8s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  49.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  50.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  59.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  59.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  58.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  54.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  53.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total= 1.0min\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  58.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total= 1.0min\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  58.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  43.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  43.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  43.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  43.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  42.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  42.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  24.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  30.3s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  29.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  30.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  26.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.4s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  24.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  44.1s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  43.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  43.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total= 1.0min\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  58.9s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  59.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  52.9s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  52.7s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  53.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  21.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.2s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  32.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  46.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=4, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  47.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  30.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  33.5s\n",
      "[CV] n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=4, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  30.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  51.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  52.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  51.7s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  28.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  27.6s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  32.0s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.8s\n",
      "[CV] n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  31.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.8s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  25.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  27.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  37.1s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  36.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=3, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  36.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  46.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  46.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function elu at 0x0000015991148D08>, total=  46.8s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  22.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  23.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.5s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  23.6s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function elu at 0x0000015991148D08>, total=  22.9s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  58.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  56.0s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.005, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  58.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  59.2s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  58.3s\n",
      "[CV] n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=5, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=661.5min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total= 1.2min\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  51.2s\n",
      "[CV] n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=100, n_hidden_layers=3, learning_rate=0.005, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  52.6s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total= 5.7min\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  43.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=3, learning_rate=0.01, dropout_rate=0.25, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  44.1s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  36.4s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  31.0s\n",
      "[CV] n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=50, n_hidden_layers=4, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=None, activation=<function relu at 0x000001599114EEA0>, total=  26.3s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  53.7s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  53.4s\n",
      "[CV] n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0> \n",
      "(?, 2) (?,)\n",
      "[CV]  n_neurons=20, n_hidden_layers=5, learning_rate=0.01, dropout_rate=None, batch_norm_momentum=0.9, activation=<function relu at 0x000001599114EEA0>, total=  54.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 844.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2) (?,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x0000015991148D08>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x00000159971E22F0>,\n",
       "       learning_rate=0.01, max_checks_without_progress=20,\n",
       "       n_hidden_layers=4, n_neurons=50,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42, show_progress=None, tensorboard_logdir=None),\n",
       "          fit_params={}, iid=True, n_iter=100, n_jobs=1,\n",
       "          param_distributions={'n_hidden_layers': [3, 4, 5], 'n_neurons': [20, 50, 100], 'activation': [<function elu at 0x0000015991148D08>, <function relu at 0x000001599114EEA0>], 'learning_rate': [0.01, 0.005], 'batch_norm_momentum': [None, 0.9], 'dropout_rate': [None, 0.25]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_search.best_estimator_.save(\"/models/titanic_rnn_best_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.elu>,\n",
       " 'batch_norm_momentum': 0.9,\n",
       " 'dropout_rate': None,\n",
       " 'learning_rate': 0.005,\n",
       " 'n_hidden_layers': 3,\n",
       " 'n_neurons': 50}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_dnn = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survival_predictions = titanic_dnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89939024390243905"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.equal(survival_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91743119266055051"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69456214 -0.27741084]\n",
      " [ 0.55506206 -1.74777532]\n",
      " [ 0.22178163 -1.96339381]\n",
      " [ 0.41168845 -2.1593678 ]\n",
      " [ 0.36622083 -2.13734388]\n",
      " [-2.55559945  0.22118406]\n",
      " [ 0.06851398 -1.97339904]\n",
      " [-0.02794443 -1.72518992]\n",
      " [-1.25824487 -0.43340653]\n",
      " [-0.62253219 -1.23301542]\n",
      " [ 0.33787864 -1.78640389]\n",
      " [ 0.18261941 -2.03560019]\n",
      " [ 0.3560189  -2.39031076]\n",
      " [ 0.34073204 -1.93704152]\n",
      " [-0.42876107 -1.19811237]\n",
      " [-0.84668845  0.78875023]\n",
      " [ 0.20234773 -1.93186522]\n",
      " [-0.45011252 -0.6826461 ]\n",
      " [ 0.57295805 -2.40776467]\n",
      " [ 0.17747237 -1.94662952]]\n",
      "Epoch: 1 Current training accuracy: 0.8000\n",
      "[[ -8.99780846  19.741745  ]\n",
      " [ -9.18759632  19.13910294]\n",
      " [  1.42311454  -9.88458347]\n",
      " [ -9.40192795  19.09752846]\n",
      " [  2.69905162 -10.37576771]\n",
      " [ -8.60425377  17.20020676]\n",
      " [ -5.65429544  10.96148491]\n",
      " [ -9.16112804  16.84039497]\n",
      " [  2.90406132  -9.91561985]\n",
      " [ -8.57962132  17.78589821]\n",
      " [  3.22679639 -10.63256741]\n",
      " [  2.88991976  -8.66174316]\n",
      " [  1.50991869 -11.41599655]\n",
      " [  1.4241991   -9.04563522]\n",
      " [  2.59627128 -10.34031868]\n",
      " [  3.40332913  -8.82416534]\n",
      " [  2.93190384  -9.72742081]\n",
      " [ -7.6870532   16.03495789]\n",
      " [  3.17717648 -12.21325302]\n",
      " [ -8.7011137   16.77780342]]\n",
      "Epoch: 11 Current training accuracy: 1.0000\n",
      "[[  2.71525526 -12.42183113]\n",
      " [  2.78592873 -11.502841  ]\n",
      " [  3.6658566  -11.04047298]\n",
      " [  1.47007799 -10.24668407]\n",
      " [ -7.61427069  15.75985432]\n",
      " [ -6.74550676  13.75797176]\n",
      " [  4.02008343 -10.63528442]\n",
      " [  1.50399601 -11.88998318]\n",
      " [ -6.91426659  14.55205345]\n",
      " [ -8.40830612  17.40119362]\n",
      " [  3.54589891 -12.56040001]\n",
      " [ -8.97942257  16.1710701 ]\n",
      " [ -6.00674772   9.99954128]\n",
      " [  3.2399435  -10.58356476]\n",
      " [  2.65071559  -8.97842979]\n",
      " [  3.64114952 -12.47976875]\n",
      " [  2.02390671 -11.23046875]\n",
      " [ -3.57453799   5.51208925]\n",
      " [-10.10157967  20.95488167]\n",
      " [ -9.09815693  19.01037025]]\n",
      "Epoch: 21 Current training accuracy: 1.0000\n",
      "[[ -8.82415581  18.2919178 ]\n",
      " [  5.52629948  -7.93471956]\n",
      " [  3.37628388 -11.47534561]\n",
      " [  3.82233787 -10.69355106]\n",
      " [  2.64016938 -14.96541309]\n",
      " [  3.37747931 -13.10446644]\n",
      " [ -5.32722855   9.79233742]\n",
      " [ -8.95096016  17.38232803]\n",
      " [ -4.5104003    6.30568171]\n",
      " [  2.76259851 -11.21780396]\n",
      " [ -6.96782589  14.46833324]\n",
      " [  2.9233551  -15.13088894]\n",
      " [  3.93610525 -10.63600922]\n",
      " [  4.84115505  -8.38836575]\n",
      " [ -5.26727676   9.12242413]\n",
      " [ -8.86866283  17.18964577]\n",
      " [  5.10651684  -8.04928589]\n",
      " [  4.0289855  -11.85926056]\n",
      " [  5.50428534  -7.85739136]\n",
      " [  3.58102179  -9.93757343]]\n",
      "Epoch: 31 Current training accuracy: 1.0000\n",
      "[[ -7.74708748  14.95870399]\n",
      " [  5.60592937  -7.82847977]\n",
      " [  2.98037553 -12.29027653]\n",
      " [ -8.77556515  16.48976517]\n",
      " [  4.42544317  -8.69874954]\n",
      " [  4.47394848 -12.9911375 ]\n",
      " [ -8.77550983  14.04258442]\n",
      " [ -7.09057331  14.55862999]\n",
      " [  3.93787956 -11.49533653]\n",
      " [  2.46589065 -12.62780285]\n",
      " [ -7.57755709  13.47695541]\n",
      " [ -7.56629801  15.72838974]\n",
      " [ -8.50484276  15.72779465]\n",
      " [  5.65801382  -9.24093819]\n",
      " [  3.47302127 -11.28491211]\n",
      " [  3.13801241 -13.42467117]\n",
      " [ -6.31239462  12.29048538]\n",
      " [ -9.52751255  18.80875969]\n",
      " [  2.35240459 -12.2024889 ]\n",
      " [ -7.06994343  14.12526226]]\n",
      "Epoch: 41 Current training accuracy: 1.0000\n",
      "[[  4.09257603 -15.91686058]\n",
      " [  0.42599607 -13.17745209]\n",
      " [ -7.67917347  14.68467426]\n",
      " [  5.78753185  -8.42035198]\n",
      " [ -9.71814537  19.96017075]\n",
      " [  4.20052767 -11.24915886]\n",
      " [-10.82922173  22.73364449]\n",
      " [  3.84334993 -13.02225208]\n",
      " [  5.95543909  -6.93932056]\n",
      " [  5.37330675 -10.28039837]\n",
      " [  2.28416991 -13.05119419]\n",
      " [ -7.12751722  14.6004467 ]\n",
      " [ -9.66080761  19.06822968]\n",
      " [  3.72116184 -11.79700565]\n",
      " [  4.08944559 -12.62618446]\n",
      " [  4.76215506  -9.72171497]\n",
      " [  3.34050798 -12.13491631]\n",
      " [  4.12785816 -13.9938097 ]\n",
      " [ -8.83963776  18.01859474]\n",
      " [ -8.01826191  15.37290382]]\n",
      "Epoch: 51 Current training accuracy: 1.0000\n",
      "[[ -7.40041018  14.67292309]\n",
      " [  4.13466072 -14.32969379]\n",
      " [  4.51614189 -14.21690559]\n",
      " [  4.30318642 -16.34114265]\n",
      " [  5.39578295 -11.95456123]\n",
      " [  3.4320128  -11.93742561]\n",
      " [  2.83280611 -13.46181774]\n",
      " [  2.85142255 -13.56554222]\n",
      " [ -8.11062622  13.11306095]\n",
      " [ -7.53289032  14.19830036]\n",
      " [  3.06403756 -12.27540493]\n",
      " [  5.84136629  -8.24731731]\n",
      " [  4.43894291  -9.83234692]\n",
      " [ -7.33986759  14.88020802]\n",
      " [-11.50567436  23.52999496]\n",
      " [  4.99835968 -10.03584766]\n",
      " [  3.90426373 -12.05967808]\n",
      " [  4.29198122 -13.79810619]\n",
      " [  4.33228683 -16.30981255]\n",
      " [  2.1236403  -12.13712978]]\n",
      "Epoch: 61 Current training accuracy: 1.0000\n",
      "[[-10.29327679  21.12674522]\n",
      " [ -9.75968742  20.5275116 ]\n",
      " [  5.32750225  -8.45227814]\n",
      " [  2.67894888 -12.68447208]\n",
      " [  4.51212549 -11.79827976]\n",
      " [-14.263834    28.57795525]\n",
      " [  5.61927128  -8.08748627]\n",
      " [ -8.91113091  16.71064186]\n",
      " [ -6.88427258   7.4469676 ]\n",
      " [  3.27632689 -13.28670979]\n",
      " [  3.40985107 -12.08386326]\n",
      " [  3.16120815 -12.61974239]\n",
      " [ -4.85934639   7.31972885]\n",
      " [  4.29978275 -11.96293354]\n",
      " [  5.24488211  -7.85850239]\n",
      " [ -8.83914852  17.10703087]\n",
      " [  4.49524069 -17.34452438]\n",
      " [  3.0953002  -10.24596882]\n",
      " [  4.05487537 -15.58513355]\n",
      " [  0.51818967 -11.94413185]]\n",
      "Epoch: 71 Current training accuracy: 1.0000\n",
      "[[  3.09167743 -13.530509  ]\n",
      " [  4.44747066 -16.72102928]\n",
      " [  3.94686556 -11.05271149]\n",
      " [-10.30449009  21.11151314]\n",
      " [  4.55134773 -14.40640736]\n",
      " [ -7.59042978  15.60466194]\n",
      " [  4.43124676 -13.15948009]\n",
      " [ -6.75197601  14.38907051]\n",
      " [ -7.13936806  14.40090466]\n",
      " [  4.12144375 -13.73211193]\n",
      " [  3.58664083 -13.16521645]\n",
      " [  4.66825914 -13.09983349]\n",
      " [  5.22735739 -10.64757252]\n",
      " [  5.326056   -11.47375488]\n",
      " [  6.19800329  -8.2057085 ]\n",
      " [ -9.00678062  17.11820412]\n",
      " [-12.42020035  24.9858551 ]\n",
      " [  4.47000313 -11.76661587]\n",
      " [  4.66630697 -13.09190845]\n",
      " [  3.83913875 -11.57367706]]\n",
      "Epoch: 81 Current training accuracy: 1.0000\n",
      "[[ -4.38310003   6.35988569]\n",
      " [ -9.61398888  20.27783012]\n",
      " [  4.87475204 -12.93541431]\n",
      " [-10.55332088  22.225811  ]\n",
      " [  2.56211734 -13.69014835]\n",
      " [-14.41154766  28.80605888]\n",
      " [ -9.93948364  18.31339455]\n",
      " [  4.84251642 -12.90373421]\n",
      " [ -6.62363434  12.83340645]\n",
      " [ -9.2093935   18.85773468]\n",
      " [ -9.41177654  19.22348785]\n",
      " [  4.75184155 -12.71592712]\n",
      " [  4.39637899 -14.23488808]\n",
      " [  2.79546499 -15.17679691]\n",
      " [  4.02318144 -15.11148548]\n",
      " [  3.32486773  -9.5934782 ]\n",
      " [  4.92645121 -13.03698444]\n",
      " [  3.11453199 -13.36231804]\n",
      " [  3.90683579 -11.71821976]\n",
      " [  4.95158482 -11.12244606]]\n",
      "Epoch: 91 Current training accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "titanic_dnn = DNNClassifier()\n",
    "titanic_dnn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93902439024390238"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survival_predictions = titanic_dnn.predict(X_test)\n",
    "np.mean(np.equal(survival_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939024390244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(survival_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
